#load required dependencies
library(rpart)
library(plotly)
library(rpart.plot)
library(RColorBrewer)
library(rattle)

#load utility function, change path if cloning
source(
  "C:/Users/Arkadeep/Documents/MBA-BITS/Sem 2/BA/wine-classifier-group2/functions/MAE.r"
)

#load dataset, change path if cloning
wineQualityDataset <-
  read.csv(
    "C:/Users/Arkadeep/Documents/MBA-BITS/Sem 2/BA/wine-classifier-group2/dataset/wine-quality-dataset.csv"
  )

#Plot histogram to check distribution of quality across dataset
plot_ly(data = wineQualityDataset,
        x = ~ quality,
        type = "histogram")

#make a copy of the dataset for box-plots and relevant manipulation
wineQualityDatasetForBoxPlot <- wineQualityDataset

#naming the box plots according to quality, to be shown alphabetically
wineQualityDatasetForBoxPlot$qual <-
  ifelse(
    wineQualityDatasetForBoxPlot$quality == 3,
    "A_qThree",
    ifelse(
      wineQualityDatasetForBoxPlot$quality == 4,
      "B_qFour",
      ifelse(
        wineQualityDatasetForBoxPlot$quality == 5,
        "C_qFive",
        ifelse(
          wineQualityDatasetForBoxPlot$quality == 6,
          "D_qSix",
          ifelse(
            wineQualityDatasetForBoxPlot$quality == 7,
            "E_qSeven",
            ifelse(
              wineQualityDatasetForBoxPlot$quality == 8,
              "F_qEight",
              "G_qNine"
            )
          )
        )
      )
    )
  )

#Box plot : Quality v/s Alcohol
plot_ly(
  data = wineQualityDatasetForBoxPlot,
  x = ~ qual,
  y = ~ alcohol,
  color = ~ qual,
  type = "box",
  colors = "Dark2"
)

#Box plot : Quality v/s Density
plot_ly(
  data = wineQualityDatasetForBoxPlot,
  x = ~ qual,
  y = ~ density,
  color = ~ qual,
  type = "box",
  colors = "Dark2"
)

#Box plot : Quality v/s Fixed acidity
plot_ly(
  data = wineQualityDatasetForBoxPlot,
  x = ~ qual,
  y = ~ fixed.acidity,
  color = ~ qual,
  type = "box",
  colors = "Dark2"
)

#Box plot : Quality v/s Volatile acidity
plot_ly(
  data = wineQualityDatasetForBoxPlot,
  x = ~ qual,
  y = ~ volatile.acidity,
  color = ~ qual,
  type = "box",
  colors = "Dark2"
)

#Box plot : Quality v/s Citric acid
plot_ly(
  data = wineQualityDatasetForBoxPlot,
  x = ~ qual,
  y = ~ citric.acid,
  color = ~ qual,
  type = "box",
  colors = "Dark2"
)

#Box plot : Quality v/s Residual sugar
plot_ly(
  data = wineQualityDatasetForBoxPlot,
  x = ~ qual,
  y = ~ residual.sugar,
  color = ~ qual,
  type = "box",
  colors = "Dark2"
)

#Box plot : Quality v/s Chlorides
plot_ly(
  data = wineQualityDatasetForBoxPlot,
  x = ~ qual,
  y = ~ chlorides,
  color = ~ qual,
  type = "box",
  colors = "Dark2"
)

#Box plot : Quality v/s Free sulphur dioxide
plot_ly(
  data = wineQualityDatasetForBoxPlot,
  x = ~ qual,
  y = ~ free.sulfur.dioxide,
  color = ~ qual,
  type = "box",
  colors = "Dark2"
)

#Box plot : Quality v/s Total Sulphur dioxide
plot_ly(
  data = wineQualityDatasetForBoxPlot,
  x = ~ qual,
  y = ~ total.sulfur.dioxide,
  color = ~ qual,
  type = "box",
  colors = "Dark2"
)

#Box plot : Quality v/s pH
plot_ly(
  data = wineQualityDatasetForBoxPlot,
  x = ~ qual,
  y = ~ pH,
  color = ~ qual,
  type = "box",
  colors = "Dark2"
)

#Box plot : Quality v/s Sulphates
plot_ly(
  data = wineQualityDatasetForBoxPlot,
  x = ~ qual,
  y = ~ sulphates,
  color = ~ qual,
  type = "box",
  colors = "Dark2"
)

#Splitting dataset into 2 parts: Training & Validation in 70:30 ratio
trainingData <- wineQualityDataset[1:457,]
validationData <- wineQualityDataset[458:653,]

#Train model on training data
modelForTrainingData <- rpart(quality ~ . , data = trainingData)

#Plot the decision tree generated by the model
fancyRpartPlot(modelForTrainingData, uniform = TRUE, main = "Unmoderated regression tree")

#Apply the model on validation data to obtain predictions
testModelPrediction <- predict(modelForTrainingData, validationData)

#Summary of predictions generated by model
print("Summary of unmoderated tree model:")
print(summary(testModelPrediction))

#Summary of actual results on validation set
print("Summary of actual data:")
print(summary(validationData$quality))

#Calculate MAE -> Refer MAE.r
sprintf(
  "Mean Absolute Error using RPart: %f",
  MAE(validationData$quality, testModelPrediction)
)

#------------PRUNING PROCESS BEGINS------------
#Display Complexity Parameter (CP) table for model generated
print("Displaying CP table for unmoderated tree model:")
printcp(modelForTrainingData)

#Select the CP value with least "XError"
sprintf("CP with least cross-validated error is: %f",
        modelForTrainingData$cptable[which.min(modelForTrainingData$cptable[, "xerror"]), "CP"])

#Plot CP v/s XError v/s Tree size graph
plotcp(modelForTrainingData)

#Prune the decision tree for better results & generate updated model
prunedTree <- prune(modelForTrainingData,
                    cp = modelForTrainingData$cptable[which.min(modelForTrainingData$cptable[, "xerror"]), "CP"])

#plot pruned decision tree
fancyRpartPlot(prunedTree, uniform = TRUE,
               main = "Pruned Regression Tree")

#test prunded decision tree model on validation data
testModelPredictionForPrunedTree <-
  predict(prunedTree, validationData)

#end of pruning process

#print summary of prunded model predictions
print("Summary of pruned tree model:")
print(summary(testModelPredictionForPrunedTree))

#print summary of actual dataset results
print("Summary of actual data:")
print(summary(validationData$quality))

#Calculate MAE of pruned decision tree -> Refer MAE.r
sprintf(
  "Mean Absolute Error using RPart Pruned Tree: %f",
  MAE(validationData$quality, testModelPredictionForPrunedTree)
)

#test for one sample
test <-
  data.frame(
    fixed.acidity = 8.5,
    volatile.acidity = 0.33,
    citric.acid = 0.42,
    residual.sugar = 10.5,
    chlorides = 0.065,
    free.sulfur.dioxide = 47,
    total.sulfur.dioxide = 186,
    density = 0.9955,
    pH = 3.10,
    sulphates = 0.40,
    alcohol = 9.9
  )

#predict results for one sample and print the same
testPrediction <- predict(prunedTree, test)
sprintf("The wine quality for the following parameters is estimated to be: %f",
        testPrediction)

#create copy of the original dataset for classification tree
copyOfDataset <- wineQualityDataset

#create a new column to show quality level based on the quantitative value of quality
# Poor: Less than 5
# Moderate: [6-7]
# Good: 7+
copyOfDataset$quality_level <-
  ifelse(
    copyOfDataset$quality < 5,
    "Poor",
    ifelse(copyOfDataset$quality >= 7,
           "Good",
           "Moderate")
  )

#Splitting dataset into 2 parts: Training & Validation in 70:30 ratio
copyOfTrainingData <- copyOfDataset[1:457,]
copyOfValidationData <- copyOfDataset[458:653,]

#Build classification tree model
classificationTreeModel <-
  rpart(
    quality_level ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol ,
    data = copyOfTrainingData
  )

#Plot classification tree model
fancyRpartPlot(classificationTreeModel, uniform = TRUE, main = "Classification tree")

#Apply classification tree model to predict results on validation data
classificationPredictionModel <-
  predict(classificationTreeModel, copyOfValidationData)
print(classificationPredictionModel)

#Create confusion matrix of model before pruning
print("Confusion matrix before pruning:")
table(round(testModelPrediction), validationData$quality)

#Create confusion matrix of model after pruning
print("Confusion matrix after pruning:")
table(round(testModelPredictionForPrunedTree),
      validationData$quality)
